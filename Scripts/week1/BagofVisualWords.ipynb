{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first read the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'../../Databases/MIT_split/train/Opencountry/fie26.jpg'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_filenames[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create a SIFT object detector and descriptor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute a k-means clustering on the descriptor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MiniBatchKMeans(batch_size=2560, compute_labels=False, n_clusters=128,\n                random_state=42, reassignment_ratio=0.0001, verbose=False)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, for each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=np.bincount(words,minlength=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a k-nn classifier and train it with the train descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(metric='euclidean', n_jobs=-1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up computing the test descriptors and compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=np.bincount(words,minlength=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.407682775712516\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction, with PCA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.14250309789344\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels) \n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.727385377943\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we repeat the previous steps, but in this case we compute the keypoints with DENSE method, by default we initialize\n",
    "the keypoint detector with 20 pixels width. The key points are separated by 20 pixels and we compute the keypoints with 5\n",
    "different scales.\n",
    "\n",
    "After this, we will compare the accuracy between SIFT keypoints and DENSE keypoints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.34944237918215\n",
      "74.96902106567535\n",
      "79.67781908302355\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "class DenseDetector():\n",
    "    def __init__(self, step_size=20, feature_scale=20, img_bound=20):\n",
    "        # Create a dense feature detector\n",
    "        self.initXyStep = step_size\n",
    "        self.initFeatureScale = feature_scale\n",
    "        self.initImgBound = img_bound\n",
    "\n",
    "    def detect(self, img):\n",
    "        keypoints = []\n",
    "        rows, cols = img.shape[:2]\n",
    "        for x in range(self.initImgBound, rows, self.initFeatureScale):\n",
    "            for y in range(self.initImgBound, cols, self.initFeatureScale):\n",
    "                keypoints.append(cv2.KeyPoint(float(x), float(y), self.initXyStep))\n",
    "        return keypoints\n",
    "\n",
    "SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=300)\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt = DenseDetector(10, 10, 5).detect(gray)\n",
    "    kpt,des=SIFTdetector.compute(gray,kpt)\n",
    "\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n",
    "\n",
    "k = 128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)\n",
    "\n",
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt = DenseDetector(10, 10, 5).detect(gray)\n",
    "    kpt,des=SIFTdetector.compute(gray,kpt)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels)\n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy is more better with DENSE keypoints that SIFT keypoints. The main difference is that with DENSE\n",
    "method, we compute a descriptors with a fixed with and the descriptors fit the image size.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}