{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first read the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Databases/MIT_split/train/Opencountry/fie26.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_filenames[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We create a SIFT object detector and descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute a k-means clustering on the descriptor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=2560, compute_labels=False, n_clusters=128,\n",
       "                random_state=42, reassignment_ratio=0.0001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, for each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=np.bincount(words,minlength=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a k-nn classifier and train it with the train descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_jobs=-1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up computing the test descriptors and compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=np.bincount(words,minlength=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.90334572490706\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction, with PCA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.753407682775716\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels) \n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.10780669144982\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat the previous steps, but in this case we compute the keypoints with DENSE method, by default we initialize\n",
    "the keypoint detector with 20 pixels width. The key points are separated by 20 pixels and we compute the keypoints with 5\n",
    "different scales.\n",
    "\n",
    "After this, we will compare the accuracy between SIFT keypoints and DENSE keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.09293680297398\n",
      "74.59727385377943\n",
      "80.17348203221809\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "class DenseDetector():\n",
    "    def __init__(self, step_size=20, feature_scale=20, img_bound=20):\n",
    "        # Create a dense feature detector\n",
    "        self.initXyStep = step_size\n",
    "        self.initFeatureScale = feature_scale\n",
    "        self.initImgBound = img_bound\n",
    "\n",
    "    def detect(self, img):\n",
    "        keypoints = []\n",
    "        rows, cols = img.shape[:2]\n",
    "        for x in range(self.initImgBound, rows, self.initFeatureScale):\n",
    "            for y in range(self.initImgBound, cols, self.initFeatureScale):\n",
    "                keypoints.append(cv2.KeyPoint(float(x), float(y), self.initXyStep))\n",
    "        return keypoints\n",
    "\n",
    "SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=300)\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt = DenseDetector(10, 10, 5).detect(gray)\n",
    "    kpt,des=SIFTdetector.compute(gray,kpt)\n",
    "\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n",
    "\n",
    "k = 128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)\n",
    "\n",
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    kpt = DenseDetector(10, 10, 5).detect(gray)\n",
    "    kpt,des=SIFTdetector.compute(gray,kpt)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels)\n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that the accuracy is more better with DENSE keypoints that SIFT keypoints. The main difference is that with DENSE\n",
    "method, we compute a descriptors with a fixed with and the descriptors fit the image size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import cv2\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))\n",
    "\n",
    "features = np.arange(50,600,50)\n",
    "iteration_accuracy = []\n",
    "for nfeatures in features:\n",
    "    SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures= int(nfeatures))\n",
    "\n",
    "    Train_descriptors = []\n",
    "    Train_label_per_descriptor = []\n",
    "\n",
    "    for filename,labels in zip(train_images_filenames,train_labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "\n",
    "        Train_descriptors.append(des)\n",
    "        Train_label_per_descriptor.append(labels)\n",
    "\n",
    "    D=np.vstack(Train_descriptors)\n",
    "\n",
    "    k = 128\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    codebook.fit(D)\n",
    "\n",
    "    visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "    for i in range(len(Train_descriptors)):\n",
    "        words=codebook.predict(Train_descriptors[i])\n",
    "        visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "    knn.fit(visual_words, train_labels)\n",
    "\n",
    "    visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "    for i in range(len(test_images_filenames)):\n",
    "        filename=test_images_filenames[i]\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "        words=codebook.predict(des)\n",
    "        visual_words_test[i,:]=np.bincount(words,minlength=k)\n",
    "\n",
    "    accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=64)\n",
    "    VWpca = pca.fit_transform(visual_words)\n",
    "    knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "    knnpca.fit(VWpca, train_labels)\n",
    "    vwtestpca = pca.transform(visual_words_test)\n",
    "    accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "    knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "    knnlda.fit(VWlda, train_labels)\n",
    "    vwtestlda = lda.transform(visual_words_test)\n",
    "    accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "    iteration_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we test the process with different amount of features to compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkXUlEQVR4nO3deXxU9bnH8c/Dvq+J7BD2RYSAAUFwwxW3at1qW1cU932vt9Zu9rpV295eK9q6FVcU8aoo1oq7QoBAwiKbIIQAYQt7IMlz/5iDTWmAScjkzPJ9v17zypwzc+Y8vzB5+M1vfuf5mbsjIiKpo1bYAYiISM1S4hcRSTFK/CIiKUaJX0QkxSjxi4ikmDphBxCNtLQ0z8jICDsMEZGEMmPGjHXunr73/oRI/BkZGWRnZ4cdhohIQjGz5RXt11CPiEiKUeIXEUkxSvwiIilGiV9EJMXENPGbWQszm2BmC8xsvpkNN7P7zSzfzHKC26mxjEFERP5drGf1/AF4z93PNbN6QCPgZOAxd38kxucWEZEKxCzxm1lz4GjgUgB33wXsMrNYnVJERKIQy6GerkAh8IyZzTKzp82scfDY9WY2x8z+ZmYtKzrYzMaaWbaZZRcWFsYwTBGR+OLuzF1VxG/fmcf6rcXV/vqxTPx1gMHAE+4+CNgG3A08AXQHMoEC4NGKDnb3ce6e5e5Z6en/ceGZiEjSKSjawV8+XsIpj3/KaX/8jGe/WEbOik3Vfp5YjvGvBFa6+9fB9gTgbndfs+cJZvYU8HYMYxARiWtbi0t4L281E2et5Isl63GHQZ1b8OsfHMrpA9rTsnG9aj9nzBK/u682sxVm1tvdvwGOB+aZWTt3LwiedjaQF6sYRETiUUlpGZ8uXsfEmflMmbeanbvL6NyqETeO6snZgzqQkdb4wC9yEGI9q+cGYHwwo2cpcBnwRzPLBBxYBlwV4xhEREIXGbffzBsz83lr9irWbS2mecO6nDO4Iz8c3IHBnVtSU5NfYpr43T0HyNpr90WxPKeISDzJ37SDN2fl8+asfBat3Uq92rUY1ecQzh7cgWN7p1O/Tu0ajykhqnOKiCSSLTt3Mzl3NW/MWsnX327AHbK6tOS3Z/fntMPa0aJR9Y/bV4YSv4hINdhdWsaniwp5Y2Y+H8xbQ3FJGV3TGnPLCb04K7MDnVs3CjvE7ynxi4hUkbszZ2URE2fl83+zV7F+2y5aNqrLBUM6cfagDmR2alFj4/aVocQvIlJJKzZsZ1JOPm/Mymdp4Tbq1anFiX3bcNagDhzTK516deK7/qUSv4hIFIp27Obd3AImzspn2rcbABjatRVjj+rG6MPa0bxh3ZAjjJ4Sv4jEveKSUt6Ymc/G7btq/NzuMHdVEf+Yv5ZdJWV0T2/MHSf35syB7enUKn7G7StDiV9E4lrOik3cOWE2C9dsDS2G1o3r8eOhnfnh4A4c1qF5XI7bV4YSv4jEpZ27S3nsg4U89elS2jRrwDOXDmF499ahxFKvdi1q1UrsZF+eEr+IxJ0Zyzdwx2tzWLpuGxcO7cQ9p/alWYPEGUOPd0r8IhI3tu8q4ZH3F/LMF9/SvnlD/j7mCEb2TAs7rKSjxC8iceGrpeu56/U5LF+/nYuHd+HOU/rQpL5SVCzotyoiodpaXMKDkxfwwlfL6dK6ES+PHcawbuGM5acKJX4RCc1ni9Zx1+tzWFW0g8tHdOX2k3vRqJ7SUqzpNywiNW7zzt088M58Xp6+gm7pjZlw9XAO79Iq7LBShhK/iNSoj75Zy8/eyGXN5p1cdUw3bjmhFw3q1nxp4lSmxC8iNaJo+25++fZc3piZT89DmvDEtSPI7NQi7LBSkhK/iMTclLmruffNPDZs28X1x/XghuN7hLIAiUQo8YtIzGzYtov735rLW7NX0bddM565dAj9OzQPO6yUp8QvIjHxzpwC7puUx+adu7nlhF5cc2z3uC9XnCqU+EWkWhVuKea+SXlMzlvNYR2aM/68I+jTtlnYYUk5SvwiUi3cnbdmr+L+t+ayrbiUO07uzVVHd6NObfXy440Sv4gctDWbd3LvxFz+MX8tgzq34OFzB9DjkKZhhyX7oMQvIlXm7kyYsZJfvz2P4pIy7j21L5eP7ErtJCphnIyU+EWkSlZt2sHPJuYy9ZtChmS05MFzBtAtvUnYYUkUlPhFpFLcnZenr+C378yntMy5/4x+XDw8I6kWKkl2SvwiEpXtu0rI+W4Tf566mM8Xr2d4t9Y8eM4AOrdOzHVnU5kSv4hUaHXRTrKXbyB72UZmLN/IvILNlJY5jevV5jdn9efHQzurl5+glPhFhNIyZ+GaLWQv20D28o1kL9tI/qYdADSoW4uBHVtw9THdyOrSisMzWmoZxASnxC+SgvYM22Qv30j28o3MWr6RLcUlAKQ3rU9Wl5ZcNiKDrIxWHNq+GXU1Fz+pKPGLpIB9DduYQa9DmnJGZnuyurQkq0srOrVqiJmGcJKZEr9IkjnQsE1mpxZcc0x3Ds9oyeDOLWneUMM2qSamid/MWgBPA/0BBy4HvgFeATKAZcD57r4xlnGIJLNoh22GZLSin4ZthNj3+P8AvOfu55pZPaAR8DPgQ3f/bzO7G7gbuCvGcYgkjQ3bdvHV0vVM+3aDhm2kSmKW+M2sOXA0cCmAu+8CdpnZD4Bjg6c9B0xFiV9kn3bsKmXasg18sXgdny1ex7yCzbhr2EaqLpY9/q5AIfCMmQ0EZgA3AW3cvSB4zmqgTUUHm9lYYCxA586dYximSHwpKS1j9sqi7xP9rO82sau0jLq1jcGdW3LLCb0Y0aM1Azq20LCNVEksE38dYDBwg7t/bWZ/IDKs8z13dzPzig5293HAOICsrKwKnyOSDNydRWu38vnidXy+eB1fL93w/Rj9oe2bcemIDEb0SGNIRksa1dN8DDl4sXwXrQRWuvvXwfYEIol/jZm1c/cCM2sHrI1hDCJxadWmHd8n+s+XrKdwSzEAXVo34vSB7RnZI43h3VvTqnG9kCOVZBSzxO/uq81shZn1dvdvgOOBecHtEuC/g5+TYhWDSLwo2r6bL5dGhm6+WLyepeu2AdC6cT2O7JHGyB6tObJ7Gp1aqe6NxF6sPzfeAIwPZvQsBS4DagGvmtkYYDlwfoxjEKlxO3eXkr1sI58vifTqc/OLcIdG9WpzRNdW/PiIzozokUbvNk1V70ZqXEwTv7vnAFkVPHR8LM8rUtNKy5zc/KLvh2+yl29kV0kZdWoZgzq34MZRPRnZM42BHVtowXEJnb4pEqmi/E07+HD+Gj5btI6vlq5n887IF7J92jblomFdGNkjjSFdW9Gkvv7MJL7oHSlSCSs2bGdyXgHv5K5m9opNAHRo0ZDR/dsxomcaR3ZvTVqT+uEGKXIASvwiB7B8/TbezV3Nu7kF5OYXAdC/QzPuPKU3pxzalq5pjXV1rCQUJX6RCny7bhvv5hbwbm4Bc1dtBmBgx+bcM7oPo/u306pTktCU+EUCi9du/T7ZL1i9BYBBnVtw76l9GX1YWzq2VLKX5KDELylt4Zot3yf7hWu2ApDVpSU/P70fo/u3pX2LhiFHKFL9lPglpbg7C1ZvYXJuAe/mrWbx2q2YwZCMVtx/Rj9O6d+Ots0bhB2mSEwp8UvSc3fmFWzm3dwCJueuZum6bdQyOKJray4Z3oWTD23LIc2U7CV1KPFLUnJ38vI3805uAZPzCli+fju1axnDu7VmzFFdOalfW9KbatqlpCYlfkka7s7slUXBME4BKzbsoHYt48jurbnmmO6c2K8NrTXHXkSJXxLfojVbeGX6CibnrSZ/0w7q1jZG9EjjhlE9ObFvG1qqwqXIv1Hil4SWl1/E+U9+SUmpc1TPNG45sRcn9m1D80ZaiUpkX5T4JWEVFO1gzHPTadGwLq9feyTtmmvqpUg0lPglIW3ZuZvLnpnO9uJSXrtmuJK+SCUo8UvC2V1axnUvzmLx2q08e9lQ+rRtFnZIIglFiV8Sirvz8zfz+GRhIQ+dM4CRPdPCDkkk4WhFCEkoT3y8hJenr+CGUT04f0insMMRSUhK/JIw3pq9iofe+4YfZLbn1hN7hR2OSMJS4peEMH3ZBm5/dTZDM1rx0LkDVP9e5CAo8UvcW1q4lSufz6Zjq4aMu/hw6tepHXZIIglNiV/i2vqtxVz27HRqm/HspUNp0UhX4YocLM3qkbi1c3cpVz6fzeqinbw0dphWvRKpJkr8EpfKypxbX81h1opN/O+PBzO4c8uwQxJJGhrqkbj04PsLeDd3dbDsYbuwwxFJKkr8Enf+/tVynvx4KRcN68KYkV3DDkck6SjxS1z5aMFa7puUx6g+h/CLM/pp2qZIDCjxS9zIyy/iuhdn0rddM/504SDq1NbbUyQW9JclcWHVpn+VWP7bpUNoXF/zDkRiRX9dErotO3dz+bP/KrHcRgufi8SUEr+EandpGdeOn6kSyyI1SIlfQrOnxPKni9apxLJIDdIYv4Tmf6dGSixff5xKLIvUpJgmfjNbZma5ZpZjZtnBvvvNLD/Yl2Nmp8YyBolPk3Lyefj9SInl205SiWWRmlQTQz3Hufu6vfY95u6P1MC5JQ5NX7aBO16boxLLIiE5YI/fzM4wMw0JSbVQiWWR8EWT0C8AFpnZQ2bWp5Kv78AUM5thZmPL7b/ezOaY2d/MrMLqW2Y21syyzSy7sLCwkqeVeKQSyyLx4YCJ391/CgwClgDPmtmXQVJuGsXrj3T3wcBo4DozOxp4AugOZAIFwKP7OO84d89y96z09PToWiNxq3yJ5acuyVKJZZEQRTWE4+6bgQnAy0A74GxgppndcIDj8oOfa4GJwFB3X+Pupe5eBjwFDD2I+CUBlC+x/PgFmSqxLBKyaMb4zzSzicBUoC6R5D0aGAjctp/jGu/5VGBmjYGTgDwzK19j92wgr+rhSyJ48L1IieWfjVaJZZF4EM2snnOIzML5pPxOd99uZmP2c1wbYGIwY6MO8KK7v2dmL5hZJpHx/2XAVVUJXBLDC18t58lPIiWWrzhKJZZF4kE0if9+ImPxAJhZQ6CNuy9z9w/3dZC7LyXyqWDv/RdVIU5JQB8tWMsvVGJZJO5EM8b/GlBWbrs02CeyTyqxLBK/ovlrrOPuu/ZsBPc1D0/2adWmHVz+rEosi8SraBJ/oZmduWfDzH4A7H0lrgjwrxLLO3aV8rfLhqjEskgciqYrdjUw3sz+BzBgBXBxTKOShFS+xPIzlw1RiWWROHXAxO/uS4BhZtYk2N4a86gk4ZQvsfzgOYdxVE9ddCcSr6IafDWz04BDgQZ7Zma4+69iGJckkN2lZdw3Ke/7EssXDOkcdkgish8HTPxm9hegEXAc8DRwLjAtxnFJgti8czfXjZ/Jp4vWce2x3VViWSQBRNPjP9LdB5jZHHf/pZk9CkyOdWAS/1Zs2M7lz07n23XbeOicAVpMRSRBRJP4dwY/t5tZe2A9kXo9ksJyVmziiuemU1xSxnOXD2VEDy2bKJIookn8/2dmLYCHgZlESi08FcugJL5Nzi3g5ldyOKRZfV4eO4weh0RTqFVE4sV+E3+wAMuH7r4JeN3M3gYauHtRTQQn8cXdGffJUn43eQGDOrfgqYuzSGtSP+ywRKSS9pv43b3MzP5MpB4/7l4MFNdEYBJf9szceWnaCk4b0I5HzxtIg7paPUskEUUz1POhmZ0DvOHuHuuAJP6Un7lz3XHdue3E3tSqpYJrIokqmsR/FXArUGJmO4lcvevurssyU8CKDdsZ89x0lhZq5o5Isojmyl19c5eiNHNHJDlFcwHX0RXt33thFkkumrkjkryiGeq5o9z9BkTWyJ0BjIpJRBIqzdwRSX7RDPWcUX7bzDoBj8cqIAmPZu6IpIaqrJCxEuhb3YFIuDRzRyR1RDPG/yciV+tCZOGWTCJX8EqS0MwdkdQSTY8/u9z9EuAld/88RvFIDYvM3MmmuKRUM3dEUkQ0iX8CsNPdSwHMrLaZNXL37bENTWJtcm4Bt7yaQ3rT+rw89gjN3BFJEdGsufsh0LDcdkPgH7EJR2qCu/Pkx0u4ZvxM+rZrxsRrRyjpi6SQaHr8Dcovt+juW82sUQxjkhiKzNyZy0vTvtPMHZEUFU3i32Zmg919JoCZHQ7siG1YEgt7r5Z1+0mauSOSiqJJ/DcDr5nZKiJ1etoCF8QyKKl+KzdGVsvSzB0RieYCrulm1gfoHez6xt13xzYsqU6auSMi5R3wy10zuw5o7O557p4HNDGza2MfmlSHybkF/GjclzSoW4uJ1x6ppC8iUc3quTJYgQsAd98IXBmziKRa7Jm5c+2LkZk7b16nmTsiEhHNGH9tM7M9i7CYWW2gXmzDkoOhmTsisj/RJP73gFfM7Mlg+ypgcuxCkoOhmTsiciDRJP67gLHA1cH2HCIzew7IzJYBW4BSoMTds8ysFfAKkAEsA84Pho/kIJWUljHm2enM+m6TZu6IyD4dcIzf3cuAr4kk6aFE6vDPr8Q5jnP3THfPCrbvBj50955Ergq+u1IRyz49MXUJ05dt5KFzlfRFZN/22eM3s17AhcFtHZFeOu5+3EGe8wfAscH954CpRD5VyEHIWbGJxz9cxJkD2/PDwR3DDkdE4tj+evwLiPTuT3f3ke7+JyJDNpXhwBQzm2FmY4N9bdy9ILi/GmhT0YFmNtbMss0su7CwsJKnTS3biku45ZUc2jStz6/P6h92OCIS5/aX+H8IFAAfmdlTZnY8kSt3K2Okuw8GRgPX7b1+bzBTyCs60N3HuXuWu2elp6dX8rSp5TfvzGfZ+m08en4mzRvWDTscEYlz+0z87v6mu/8I6AN8RKR0wyFm9oSZnRTNi7t7fvBzLTCRyHcEa8ysHUDwc+1BtSDFTZm7mpemfcfYo7sxvHvrsMMRkQQQzZe729z9xWDt3Y7ALKIYkzezxmbWdM994CQgD3gLuCR42iXApCrGnvLWbtnJ3W/k0q9dM247sfeBDxARoZJr7gbTLscFtwNpA0w0sz3nedHd3zOz6cCrZjYGWA6cX7mQBSJX5t7x2hy2FZfwxwszqVcnmouwRUSqtth6VNx9KTCwgv3rgeNjdd5U8fyXy/l4YSG/+sGhKsUgIpWibmICWrRmCw+8O59je6dz0bAuYYcjIglGiT/BFJeUctPLOTSuX4eHzh1AMJQmIhK1mA31SGz8fspC5hVs5qmLszikaYOwwxGRBKQefwL5Ysk6xn26lAuHdubEfhVe9yYickBK/AmiaPtubnt1Nl1bN+bnp/cNOxwRSWAa6kkA7s69b+ZSuKWYN649kkb19M8mIlWnHn8CeDMnn7fnFHDzCT0Z0LFF2OGISIJT4o9zKzZs574355LVpSXXHNsj7HBEJAko8cex0jLntldn48BjF2RSWytpiUg10GBxHPvLx0uYtmwDvz9/IJ1aNQo7HBFJEurxx6k5Kzfx2AcLOW1AO84e1CHscEQkiSjxx6Htu0q4+eUc0pvW54GzDtPVuSJSrTTUE4d++858vl2/jfFXHEHzRlpYRUSql3r8ceYf89Yw/uvvuPKobhzZPS3scEQkCSnxx5HCLcXc9foc+rZrxm0n9Qo7HBFJUhrqiRPuzp0TZrO1uISXfpRJ/Tq1ww5JRJKUevxx4u9fLeejbwq5Z3QferXRwioiEjtK/HFg8dot/Oad+RzTK51LjswIOxwRSXJK/CHbVVLGza9EFlZ5WAuriEgN0Bh/yH7/wULy8jfz5EWHc0gzLawiIrGnHn+Ivlq6nic/WcKPhnTi5EPbhh2OiKQIJf6QFO3Yza2v5NClVSN+fnq/sMMRkRSioZ6Q3DcpjzVbiplw9XAa19c/g4jUHPX4QzApJ59JOau46fieDOrcMuxwRCTFKPHXsJUbt/NfE/M4vEtLrj22e9jhiEgKUuKvQaVlzq17FlY5P5M6tfXrF5Gap8HlGvTkJ0uY9u0GHjlvIJ1ba2EVEQmHupw1JC+/iN9PWciph7XlnMFaWEVEwqPEXwN27CrlxpdnkdakPg+crYVVRCRcGuqpAQ+8O5+lhZGFVVo0qhd2OCKS4tTjj7F/LljDC18t54qRXRnRQwuriEj4Yp74zay2mc0ys7eD7WfN7FszywlumbGOISzrthZz54Q59GnblDtO6R12OCIiQM0M9dwEzAealdt3h7tPqIFzh8bduWvCHDbvLGH8FcO0sIqIxI2Y9vjNrCNwGvB0LM8Tj8Z//R0fLljL3af0oXdbLawiIvEj1kM9jwN3AmV77f+tmc0xs8fMrH6MY6hx8ws285t35nFUzzQu1cIqIhJnYpb4zex0YK27z9jroXuAPsAQoBVw1z6OH2tm2WaWXVhYGKswq936rcVc8Vw2zRvW5dHzBlKrlqZuikh8iWWPfwRwppktA14GRpnZ3929wCOKgWeAoRUd7O7j3D3L3bPS09NjGGb12VVSxjXjZ1K4tZhxF2VpYRURiUsxS/zufo+7d3T3DOBHwD/d/adm1g7AIlcxnQXkxSqGmvbL/5vLtG838NA5AxjYqUXY4YiIVCiMC7jGm1k6YEAOcHUIMVS7F75azvivv+OqY7px1iCVZBCR+FUjid/dpwJTg/ujauKcNenLJev55VtzOa53Onee3CfscERE9ktX7h6kFRu2c+34GXRp3Yg/XDiI2voyV0TinBL/QdhaXMIVz2VTWuY8fckQmjWoG3ZIIiIHpCJtVVRW5tz6Sg6L1m7hucuH0jWtcdghiYhERT3+Knr8HwuZMm8N/3VaP47qmRjTTUVEQIm/St6es4o//nMx52d15LIRGWGHIyJSKUr8lZSXX8Ttr83m8C4t+fVZ/bWoiogkHCX+SijcUszY57Np2agef/np4aq4KSIJSV/uRmlXSRnX/H0GG7bvYsLVR5LeNOlqy4lIilDij4K78/M388hevpE/XTiI/h2ahx2SiEiVaagnCs99sYxXsldw/XE9OGNg+7DDERE5KEr8B/DZonX8+p35nNivDbee2CvscEREDpoS/34sW7eN616cSff0xjx2QaZq64tIUlDi34ctO3dzxfPZmMHTFw+hSX19HSIiyUHZrAKlZc5NL+fw7bptvDBmKJ1bNwo7JBGRaqMefwUemfIN/1ywll+c0Y8ju6eFHY6ISLVS4t/LpJx8npi6hAuHduaiYV3CDkdEpNop8ZczZ+Um7pwwh6EZrfjlmYeqHIOIJCUl/sDazTsZ+/wM0prU54mfDqZeHf1qRCQ56ctdYOfuUsa+MIOiHbt5/Zojad1E5RhEJHmlfOJ3d+6dmEfOik088ZPB9GvfLOyQRERiKuXHM/762be8PnMlN5/Qk9GHtQs7HBGRmEvpxD/1m7U88O58Rvdvy42jeoYdjohIjUjZxL+kcCs3vDSLXm2a8sh5A1WOQURSRkom/qIdu7ny+Wzq1q7FUxdn0VjlGEQkhaRc4i8tc258aRbfrd/OEz8ZTKdWKscgIqkl5bq6D763gI8XFvLA2YdxRLfWYYcjIlLjUqrH//qMlYz7ZCkXD+/Cj4/oHHY4IiKhSJnEP/O7jdzzRi7Du7Xm56f3CzscEZHQpETiX120k6temEGb5vX5358Mpm7tlGi2iEiFkj4DRsoxZLO9uISnLx5Cy8b1wg5JRCRUSf3lrrtz1+tzmLOyiHEXHU7vtk3DDklEJHRJ3eP/y8dLmZSzittP6sVJh7YNOxwRkbgQ88RvZrXNbJaZvR1sdzWzr81ssZm9YmYxG3vp2LIh5x7ekeuO6xGrU4iIJJya6PHfBMwvt/0g8Ji79wA2AmNideIzBrbnkfMGakEVEZFyYpr4zawjcBrwdLBtwChgQvCU54CzYhmDiIj8u1j3+B8H7gTKgu3WwCZ3Lwm2VwIdKjrQzMaaWbaZZRcWFsY4TBGR1BGzxG9mpwNr3X1GVY5393HunuXuWenp6dUcnYhI6orldM4RwJlmdirQAGgG/AFoYWZ1gl5/RyA/hjGIiMheYtbjd/d73L2ju2cAPwL+6e4/AT4Czg2edgkwKVYxiIjIfwpjHv9dwK1mtpjImP9fQ4hBRCRl1ciVu+4+FZga3F8KDK2J84qIyH9K6it3RUTkP5m7hx3DAZlZIbA87DiqIA1YF3YQNSjV2gtqc6pI1DZ3cff/mBaZEIk/UZlZtrtnhR1HTUm19oLanCqSrc0a6hERSTFK/CIiKUaJP7bGhR1ADUu19oLanCqSqs0a4xcRSTHq8YuIpBglfhGRFKPEX0Vm9jczW2tmeeX2tTKzD8xsUfCzZbDfzOyPwapjc8xscHiRV52ZdTKzj8xsnpnNNbObgv1J224za2Bm08xsdtDmXwb7K1xJzszqB9uLg8czQm1AFUW7cl4StXeZmeWaWY6ZZQf7kvZ9rcRfdc8Cp+y1727gQ3fvCXwYbAOMBnoGt7HAEzUUY3UrAW5z937AMOA6M+tHcre7GBjl7gOBTOAUMxvGvleSGwNsDPY/FjwvEUW7cl6ytBfgOHfPLDdfP3nf1+6uWxVvQAaQV277G6BdcL8d8E1w/0ngwoqel8g3IpVVT0yVdgONgJnAEUSu4qwT7B8OvB/cfx8YHtyvEzzPwo69ku3sSCTRjQLeBiyZ2xvEvgxI22tf0r6v1eOvXm3cvSC4vxpoE9zvAKwo97x9rjyWKIKP9IOAr0nydgfDHjnAWuADYAn7Xknu+zYHjxcRqUKbSB4n+pXzkqG9AA5MMbMZZjY22Je07+saqc6ZitzdzSwp58qaWRPgdeBmd99cfjH7ZGy3u5cCmWbWApgI9Ak3otgpv3KemR0bcjg1aaS755vZIcAHZrag/IPJ9r5Wj796rTGzdgDBz7XB/nygU7nnJezKY2ZWl0jSH+/ubwS7k77dAO6+ichCQsMJVpILHirfru/bHDzeHFhfs5EelD0r5y0DXiYy3PP9ynnBc5KpvQC4e37wcy2R/9yHksTvayX+6vUWkVXF4N9XF3sLuDiYDTAMKCr3ETJhWKRr/1dgvrv/vtxDSdtuM0sPevqYWUMi32nMZ98ryZX/XZxLZOW5hOkpeuVXzkvo9gKYWWMza7rnPnASkEcSv69D/5IhUW/AS0ABsJvIGN8YImObHwKLgH8ArYLnGvBnImPDuUBW2PFXsc0jiYyFzgFygtupydxuYAAwK2hzHnBfsL8bMA1YDLwG1A/2Nwi2FwePdwu7DQfR9mOBt5O9vUHbZge3ucC9wf6kfV+rZIOISIrRUI+ISIpR4hcRSTFK/CIiKUaJX0QkxSjxi4ikGCV+CZ2ZuZk9Wm77djO7v5pe+1kzO/fAzzzo85xnZvPN7KMKHns4qOz5cBVeN9PMTq2eKEUilPglHhQDPzSztLADKa/clarRGANc6e7HVfDYWGCAu99RhTAyiVwrEbXgwiL9bcs+6c0h8aCEyJqmt+z9wN49djPbGvw81sw+NrNJZrbUzP7bzH5ikdr5uWbWvdzLnGBm2Wa2MKhFs6fw2sNmNj2oqX5Vudf91MzeAuZVEM+FwevnmdmDwb77iFzc9te9e/XB6zQBZpjZBcGVwK8H551uZiOC5w01sy8tUgP/CzPrbZGa978CLrBInfgLzOx+M7u93OvnmVlGcPvGzJ4ncqFZJzO7o1z79qwj0NjM3rHI+gJ5ZnZBZf+xJPGpSJvEiz8Dc8zsoUocMxDoC2wAlgJPu/tQiywQcwNwc/C8DCK1V7oDH5lZD+BiIpfaDzGz+sDnZjYleP5goL+7f1v+ZGbWnki9+cOJ1KSfYmZnufuvzGwUcLu7Z5c/xt3PNLOt7p4ZvMaLROraf2ZmnYmUNe4LLACOcvcSMzsBeMDdzwn+U8ly9+uD4+/fz++jJ3CJu39lZicF20OJXGn6lpkdDaQDq9z9tOD1mh/wtyxJR4lf4oJHqnw+D9wI7IjysOke1EgxsyXAnsSdC5QfcnnV3cuARWa2lEh1zZOAAeU+TTQnkih3AdP2TvqBIcBUdy8MzjkeOBp4M8p4AU4A+tm/Kpo2s0i10+bAc2bWk0hZjLqVeM09lrv7V8H9k4LbrGC7CZH2fQo8GnxaedvdP63CeSTBKfFLPHmcyEInz5TbV0IwJBmMW9cr91hxuftl5bbL+Pf39t51SZxIL/gGd3+//AMWKUW8rSrBR6kWMMzdd+513v8BPnL3sy2y1sHUfRz//e8j0KDc/fJxG/A7d39y7xewyFKBpwK/MbMP3f1XlW6FJDSN8UvccPcNwKv8a1k/iKyMdHhw/0yq1hM+z8xqBeP+3YismPQ+cI1FykxjZr2Cyoz7Mw04xszSzKw2cCHwcSVjmUJkGIrgvJnB3eb8q7TvpeWevwVoWm57GZGhqD0JvOs+zvM+cHnwaQIz62BmhwTDVdvd/e/Aw3teS1KLEr/Em0eB8rN7niKSbGcTqYNfld74d0SS9mTg6qC3/TSRL29nmlkekeX09vsJOBhWuptIieLZwAx3n7S/YypwI5AVfOE6D7g62P8Q8Dszm7VXHB8RGRrKCb6IfR1oZWZzgeuBhfuIdQrwIvClmeUCE4j8B3IYMM0iK4r9AvhNJeOXJKDqnCIiKUY9fhGRFKPELyKSYpT4RURSjBK/iEiKUeIXEUkxSvwiIilGiV9EJMX8P05WDSjpEC9SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(features,iteration_accuracy)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that if we increment the amount of features, the performance is better, but the computational time it's to longer,\n",
    "because the computer needs more memory to store all the descriptors values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will vary the metric used while building the K-NN classifier. In this section we will use the following metrics and compare them: Euclidean (base case), Manhattan, and Chebyshev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucliedean:\n",
      "59.603469640644356\n",
      "Manhattan:\n",
      "59.10780669144982\n",
      "Chebyshev:\n",
      "47.08798017348203\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, train_labels) \n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='manhattan')\n",
    "knn_manhattan.fit(visual_words, train_labels)\n",
    "knn_chebyshev = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='chebyshev')\n",
    "knn_chebyshev.fit(visual_words, train_labels)\n",
    "\n",
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print('Eucliedean:')\n",
    "print(accuracy)\n",
    "accuracy = 100*knn_manhattan.score(visual_words_test, test_labels)\n",
    "print('Manhattan:')\n",
    "print(accuracy)\n",
    "accuracy = 100*knn_chebyshev.score(visual_words_test, test_labels)\n",
    "print('Chebyshev:')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we also check the variations on the metric used when applying Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean:\n",
      "60.34696406443618\n",
      "Manhattan:\n",
      "57.62081784386617\n",
      "Chebyshev:\n",
      "57.249070631970255\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print('Euclidean:')\n",
    "print(accuracy)\n",
    "\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='manhattan')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print('Manhattan:')\n",
    "print(accuracy)\n",
    "\n",
    "knnpca = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='chebyshev')\n",
    "knnpca.fit(VWpca, train_labels)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print('Chebyshev:')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we also check what happens when applying Dimensionality Reduction with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean:\n",
      "64.80793060718712\n",
      "Manhattan:\n",
      "62.949194547707556\n",
      "Chebyshev:\n",
      "64.93184634448575\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print('Euclidean:')\n",
    "print(accuracy)\n",
    "\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='manhattan')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print('Manhattan:')\n",
    "print(accuracy)\n",
    "\n",
    "knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='chebyshev')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print('Chebyshev:')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without reducing dimensionality, we can see that varying the distance metrics used produces different results. In this scenario, Euclidean distance has worked the best since it takes into account the real distance between a pair of points. Manhattan distance has ranked second between the three metrics tested, this is probably due to Manhattan distance being the shortest of all the possible 'routes' inside a grid to get from point A to point B. Chebyshev distance has ranked last producing the lowest accuracy out of all the metrics used, therefore we can conclude that for bigger dimensionalities.\n",
    "\n",
    "When reducing dimensionality using PCA, we observe that the not only that the ranking remains unchanged but also that clustering has now produced better results thus increasing the accuracy.\n",
    "\n",
    "Finally, when reducing dimensionality using LDA we notice some interesting changes. Not only has the results improved accross the board, but also the gap between the results produced by the different metrics has shortened. Another noticeable change is that the ranking has shifted with Chebyshev performing the best out of all the metrics tested, although the diference in performance is not significant in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
